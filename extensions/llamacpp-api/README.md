# llama.cpp API Connector for SillyTavern
Allows local use of ggml/gguf-based models via llama.cpp (running on http://127.0.0.1:8080).

